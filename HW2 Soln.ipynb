{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW#2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_list_overlap(list1, list2):\n",
    "    \"\"\" \n",
    "        Sets are used to find the intersection.  List comprehension can also be used.\n",
    "    \"\"\"\n",
    "    overlap_list = list(set(list1) & set(list2))\n",
    "    return overlap_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW#2-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"hw2-2.csv\"\n",
    "class_scores = {}\n",
    "\n",
    "with open(csv_file, \"r\") as f:\n",
    "    for line in f:\n",
    "#         print(repr(line))\n",
    "        date, classname, score = line.strip().split(\",\")\n",
    "        print(date, classname, score)\n",
    "        class_scores[classname] = class_scores.get(classname, 0) + int(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write results to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \"results.txt\"\n",
    "\n",
    "with open(out_file, \"w\") as f:\n",
    "    for classname, score in class_scores.items():\n",
    "        f.write(f\"{classname},{score}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW#2-2 with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_df = pd.read_csv(\"hw2-2.csv\", header=None, names=['date', 'class', 'points']) \n",
    "class_sum_df = csv_df.groupby('class').sum()\n",
    "class_sum_df.to_csv(\"results_pd.txt\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW#2-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_words_from_file(filename):\n",
    "    \"\"\"\n",
    "        Arguments:\n",
    "            filename - str\n",
    "        \n",
    "        Returns:\n",
    "            word_counts - dict: word (str) -> count (int) \n",
    "\n",
    "        Read file and create dictionary of word -> count\n",
    "    \"\"\"\n",
    "    non_alpha = '?!.,;:'\n",
    "    word_counts = dict()\n",
    "\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            # remove non-alphabets\n",
    "            for c in non_alpha:\n",
    "                line=line.replace(c, \"\")\n",
    "\n",
    "            # convert to lowercase and split into words\n",
    "            words = line.strip().lower().split()\n",
    "            for word in words:\n",
    "                word_counts[word] = word_counts.get(word, 0) + 1\n",
    "    return word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_word_counts(word_counts, word_len, top_count):\n",
    "    \"\"\"\n",
    "        Arguments:\n",
    "            word_counts - dict: word (str) -> count (int)\n",
    "            word_len - int (length of word)\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "\n",
    "        Prints out the nth most frequent words of length word_len\n",
    "\n",
    "    \"\"\"\n",
    "    lst = [ (val, key) for key, val in word_counts.items() if len(key) == word_len]\n",
    "    lst.sort(reverse=True)\n",
    "\n",
    "    for val, key in lst[:top_count]:\n",
    "        print(key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15, length of word: 2\n",
      "to 408\n",
      "my 390\n",
      "of 369\n",
      "in 323\n",
      "is 167\n",
      "me 164\n",
      "so 145\n",
      "be 142\n",
      "as 121\n",
      "it 111\n",
      "by 93\n",
      "do 84\n",
      "on 80\n",
      "or 78\n",
      "no 78\n",
      "\n",
      "Top 15, length of word: 3\n",
      "and 490\n",
      "the 429\n",
      "thy 287\n",
      "for 171\n",
      "not 166\n",
      "but 163\n",
      "all 114\n",
      "you 111\n",
      "his 106\n",
      "are 69\n",
      "nor 52\n",
      "yet 51\n",
      "her 51\n",
      "art 51\n",
      "now 45\n",
      "\n",
      "Top 15, length of word: 4\n",
      "that 322\n",
      "thou 234\n",
      "with 181\n",
      "thee 162\n",
      "love 158\n",
      "when 106\n",
      "this 104\n",
      "your 100\n",
      "doth 88\n",
      "from 81\n",
      "self 76\n",
      "have 76\n",
      "then 74\n",
      "what 70\n",
      "more 64\n",
      "\n",
      "Top 15, length of word: 5\n",
      "which 108\n",
      "their 63\n",
      "shall 59\n",
      "sweet 54\n",
      "heart 49\n",
      "thine 44\n",
      "still 41\n",
      "where 40\n",
      "those 33\n",
      "being 30\n",
      "every 29\n",
      "world 27\n",
      "might 26\n",
      "since 24\n",
      "truth 22\n",
      "\n",
      "Top 15, length of word: 6\n",
      "beauty 52\n",
      "should 44\n",
      "though 29\n",
      "praise 28\n",
      "love's 26\n",
      "better 19\n",
      "time's 15\n",
      "before 15\n",
      "things 14\n",
      "gentle 14\n",
      "whilst 13\n",
      "heaven 13\n",
      "friend 12\n",
      "change 12\n",
      "within 11\n",
      "\n",
      "Top 15, length of word: 7\n",
      "nothing 19\n",
      "thought 18\n",
      "against 18\n",
      "another 9\n",
      "without 8\n",
      "flowers 8\n",
      "delight 8\n",
      "whether 7\n",
      "outward 7\n",
      "heart's 7\n",
      "blessed 7\n",
      "through 6\n",
      "strange 6\n",
      "fortune 6\n",
      "eternal 6\n",
      "\n",
      "Top 15, length of word: 8\n",
      "thoughts 18\n",
      "beauty's 18\n",
      "summer's 11\n",
      "pleasure 11\n",
      "treasure 9\n",
      "disgrace 8\n",
      "although 8\n",
      "straight 7\n",
      "sometime 6\n",
      "shouldst 6\n",
      "painting 6\n",
      "nature's 6\n",
      "heaven's 6\n",
      "argument 6\n",
      "wrinkles 5\n",
      "\n",
      "Top 15, length of word: 9\n",
      "therefore 17\n",
      "beauteous 9\n",
      "mistress' 5\n",
      "invention 5\n",
      "wherefore 4\n",
      "substance 4\n",
      "abundance 4\n",
      "to-morrow 3\n",
      "self-love 3\n",
      "posterity 3\n",
      "murd'rous 3\n",
      "knowledge 3\n",
      "infection 3\n",
      "fortune's 3\n",
      "expressed 3\n",
      "\n",
      "Top 15, length of word: 10\n",
      "themselves 6\n",
      "remembered 4\n",
      "conscience 3\n",
      "complexion 3\n",
      "unkindness 2\n",
      "unfathered 2\n",
      "triumphant 2\n",
      "temptation 2\n",
      "speechless 2\n",
      "resembling 2\n",
      "possession 2\n",
      "possessing 2\n",
      "pilgrimage 2\n",
      "perfection 2\n",
      "obsequious 2\n"
     ]
    }
   ],
   "source": [
    "word_counts = process_words_from_file('sonnet.txt')\n",
    "top_count = 15\n",
    "max_len_word = 10\n",
    "\n",
    "for i in range(2, max_len_word+1):\n",
    "    print(f\"\\nTop {top_count}, length of word: {i}\")\n",
    "    print_word_counts(word_counts, i, top_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
